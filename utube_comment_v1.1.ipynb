{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def get_youtube_comments(video_url, max_comments=100, max_scrolls=10):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--lang=ko-KR')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(20)\n",
    "\n",
    "    try:\n",
    "        driver.get(video_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        scrolls = 0\n",
    "        last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        for _ in range(max_scrolls):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            if new_height == last_height or len(driver.find_elements(By.ID, 'content-text')) >= max_comments:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        comment_elems = soup.select('#content-text')\n",
    "        comments = [c.text.strip() for c in comment_elems[:max_comments]]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëŒ“ê¸€ ë¡œë”© ì¤‘ ì˜ˆì™¸ ë°œìƒ: {video_url}\\nâ†’ {e}\")\n",
    "        comments = []\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return comments\n",
    "\n",
    "def extract_video_id(url):\n",
    "    parsed = urlparse(url)\n",
    "    return parse_qs(parsed.query).get('v', [url.split(\"v=\")[-1]])[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_file = 'youtube_metadata_250510_ê¹€ë¬¸ìˆ˜_ì´ì¬ëª…_ëŒ€ì„ .csv'\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # âœ… ë‚ ì§œ ë° í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    base_filename = os.path.basename(input_file).replace('youtube_metadata_', '').replace('.csv', '')\n",
    "    # â†’ base_filename = '250510_ê¹€ë¬¸ìˆ˜_ì´ì¬ëª…_ëŒ€ì„ '\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        video_url = row['url']\n",
    "        video_id = extract_video_id(video_url)\n",
    "        print(f\"\\nğŸ¬ {i+1}/{len(df)} | {row['title']} | ì±„ë„: {row['channel']} | ID: {video_id}\")\n",
    "\n",
    "        try:\n",
    "            comments = get_youtube_comments(video_url, max_comments=100)\n",
    "            print(f\"ğŸ—¨ï¸ {len(comments)}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "\n",
    "            if comments:\n",
    "                print(\"ğŸ“Œ ëŒ“ê¸€ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "                for preview in comments[:3]:\n",
    "                    print(f\"   - {preview}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ëŒ“ê¸€ ì—†ìŒ ë˜ëŠ” ë¹„í™œì„±í™” ì˜ìƒ\")\n",
    "\n",
    "            for c in comments:\n",
    "                all_data.append({\n",
    "                    'videoId': video_id,\n",
    "                    'title': row['title'],\n",
    "                    'channel': row['channel'],\n",
    "                    'comment': c\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {video_id} â†’ {e}\")\n",
    "\n",
    "        time.sleep(4 + random.uniform(0, 2))\n",
    "\n",
    "    df_comments = pd.DataFrame(all_data)\n",
    "\n",
    "    # âœ… ë¯¸ë¦¬ë³´ê¸°\n",
    "    print(\"\\nğŸ“ ìµœì¢… ëŒ“ê¸€ í†µí•© ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(df_comments.head(3))\n",
    "\n",
    "    # âœ… ìë™ íŒŒì¼ëª… ì„¤ì •\n",
    "    output_file = f'youtube_comments_{base_filename}.csv'\n",
    "    df_comments.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nâœ… ì´ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(df_comments)}ê±´ â†’ {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
