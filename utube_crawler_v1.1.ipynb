{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d065b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# âœ… 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(dotenv_path=r\"c:/Users/NOTE2/ì¡°ì›C&I/ê°œì¸biz/phytho code/youtube analytics/.env\")\n",
    "API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# âœ… 2. í‚¤ì›Œë“œë³„ ì˜ìƒ ID ìˆ˜ì§‘\n",
    "def get_video_ids_by_keyword(keyword, max_results, start_date, end_date):\n",
    "    request = youtube.search().list(\n",
    "        q=keyword,\n",
    "        part='id',\n",
    "        type='video',\n",
    "        maxResults=max_results,\n",
    "        order='date',\n",
    "        publishedAfter=start_date,\n",
    "        publishedBefore=end_date\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return [item['id']['videoId'] for item in response['items']]\n",
    "\n",
    "# âœ… 3. ì˜ìƒ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘\n",
    "def get_video_details(video_ids, keyword):\n",
    "    video_data = []\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        ids = video_ids[i:i+50]\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,statistics,contentDetails',\n",
    "            id=','.join(ids)\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            stats = item.get('statistics', {})\n",
    "            snippet = item['snippet']\n",
    "            video_data.append({\n",
    "                'keyword': keyword,\n",
    "                'title': snippet['title'],\n",
    "                'channel': snippet['channelTitle'],\n",
    "                'pub_date': snippet['publishedAt'],\n",
    "                'counts': stats.get('viewCount', '0'),\n",
    "                'likes_count': stats.get('likeCount', '0'),\n",
    "                'comment_count': stats.get('commentCount', '0'),\n",
    "                'url': f\"https://www.youtube.com/watch?v={item['id']}\"\n",
    "            })\n",
    "    return video_data\n",
    "\n",
    "# âœ… 4. ì‹¤í–‰ ë° ì €ì¥\n",
    "if __name__ == '__main__':\n",
    "    keywords = [\"ê¹€ë¬¸ìˆ˜ í›„ë³´ ë“±ë¡\", \"ì´ì¬ëª… í›„ë³´ ë“±ë¡\", \"ëŒ€ì„  í›„ë³´ ë“±ë¡\"]\n",
    "    start_date = \"2025-05-10T00:00:00Z\"\n",
    "    end_date = \"2025-05-11T23:59:59Z\"\n",
    "    max_results = 30\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        print(f\"\\nğŸ” '{keyword}' ì˜ìƒ ìˆ˜ì§‘ ì¤‘...\")\n",
    "        video_ids = get_video_ids_by_keyword(keyword, max_results, start_date, end_date)\n",
    "        video_details = get_video_details(video_ids, keyword)\n",
    "        print(f\"âœ… {len(video_details)}ê±´ ìˆ˜ì§‘ë¨\")\n",
    "        all_results.extend(video_details)\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # âœ… ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥\n",
    "    print(\"\\nğŸ“‹ ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(df[['keyword', 'title', 'channel', 'pub_date', 'url']].head(5))\n",
    "\n",
    "    # âœ… ë‚ ì§œ ë° í‚¤ì›Œë“œ ìš”ì•½ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±\n",
    "    date_tag = start_date[2:10].replace('-', '')  # '250510'\n",
    "    keyword_tag = '_'.join([kw.split()[0] for kw in keywords])  # 'ê¹€ë¬¸ìˆ˜_ì´ì¬ëª…_ëŒ€ì„ '\n",
    "    output_file = f\"youtube_metadata_{date_tag}_{keyword_tag}.csv\"\n",
    "\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nâœ… ì „ì²´ {len(df)}ê±´ ì €ì¥ ì™„ë£Œ â†’ {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
